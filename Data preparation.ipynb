{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis data preparation\n",
    "This notebook organises data preparation.\n",
    "\n",
    "### Inputs\n",
    "The `settings.json` file contains all necessary local variables and directories for data files. TODO: Template.\n",
    "\n",
    "Edit `lang_map` and `month_map` if necessary. Obtain list of values using `df['TITLE'].value_counts()` in order to find the values that crash the script if necessary. Errors occur in the conversion to `datetime.date` if month is wrongly specified and can therefore not be converted to an integer value in the range [1:12]\n",
    "\n",
    "### LexisParse\n",
    "The `LexisParse` class parses LexisNexis files with the `.txt` extension to dicts with all metadata. These are then summarised in a pandas `DataFrame` for easy manipulation and export (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#Imports\n",
    "import json\n",
    "import pandas as pd\n",
    "from lexisnexisparse import LexisParser\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "#Settings need to include:\n",
    "#    lexisnexis_source - source directory for LexisNexis files (cannot be shared openly due to copyright regulations)\n",
    "settings_file = \"D:/thesis/settings - nl.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation\n",
    "\n",
    "#Read settings\n",
    "settings = json.loads(open(settings_file).read())[\"settings\"]\n",
    "\n",
    "#LexisNexis file list\n",
    "ln_files = [settings['lexisnexis_source']+fname for fname in os.listdir(settings['lexisnexis_source']) if fname.lower().endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Parsing LexisNexis Files and placing them in a pandas DataFrame\n",
    "lp = LexisParser()\n",
    "\n",
    "df = pd.concat([pd.DataFrame(lp.parse_file(file)) for file in ln_files], ignore_index = True)\n",
    "    \n",
    "#Translating variables from text to more useful values\n",
    "\n",
    "##Length\n",
    "words_pattern = re.compile(' words| woorden')\n",
    "df['LENGTH'] = df['LENGTH'].apply(lambda x: int(re.sub(words_pattern,'',x)) if isinstance(x,str) else -1)\n",
    "\n",
    "##Language\n",
    "lang_map = {'ENGLISH': 'en', 'English': 'en', 'English english': 'en'}\n",
    "df['LANGUAGE'] = df['LANGUAGE'].map(lang_map)\n",
    "\n",
    "##Date\n",
    "re_day = re.compile(\"(?<!\\d)\\d{1,2}(?!\\d)\")\n",
    "month_map = {'january' : 1, 'february' : 2, 'march' : 3, 'april' : 4, 'may' : 5, 'june' : 6, 'july' : 7,\n",
    "            'august' : 8, 'september' : 9, 'october' : 10, 'november' : 11, 'december' : 12, '': -1,\n",
    "            'januari' : 1, 'februari' : 2, 'maart' : 3, 'mei' : 5, 'juni' : 6, 'juli' : 7, 'augustus' : 8,\n",
    "            'oktober' : 10}\n",
    "\n",
    "df['MONTH'] = df['DATE'].apply(lambda x: re.search(\"[a-z]+\",x)[0] if re.search(\"[a-z]+\",x) is not None else \"\")\n",
    "df['MONTH'] = df['MONTH'].map(month_map)\n",
    "df['YEAR'] = df['DATE'].apply(lambda x: int(re.search(\"[0-9]{4}\",x)[0]) if re.search(\"[0-9]{4}\",x) is not None else -1)\n",
    "df['DAY'] = df['DATE'].apply(lambda x: int(re.search(re_day,x)[0]) if re.search(re_day,x) is not None else -1)\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if (df.at[i,'MONTH'] > 0) and (df.at[i,'DAY'] > 0) and (df.at[i,'YEAR'] > 0):\n",
    "        df.at[i,'DATE_dt'] = datetime.date(year = df.at[i,'YEAR'], day = df.at[i,'DAY'], month = df.at[i,'MONTH'])\n",
    "\n",
    "#Dropping duplicates by mostly everything but TEXT (to save time). Medium shoyld also be excluded, because\n",
    "#different regional versions of newspapers have differend MEDIUM values, while publishing identical articles.\n",
    "df.drop_duplicates(subset = ['SECTION','BYLINE','HEADLINE','HIGHLIGHT','LENGTH','DATE_dt'], inplace = True)\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "del re_day, month_map, lang_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data\n",
    "df.to_json(settings['data_json'], compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
