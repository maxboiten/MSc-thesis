{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlite_db import thesisDB, corpusDB, enclose, docData\n",
    "from pynlpl.clients.frogclient import FrogClient\n",
    "from lexisnexisparse import LexisParser\n",
    "import json\n",
    "import pandas as pd\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os\n",
    "\n",
    "settings_file = 'D:/thesis/settings - nl_final.json'\n",
    "frogip = '192.168.33.10'\n",
    "frogport = 9772\n",
    "\n",
    "#Read settings\n",
    "settings = json.loads(open(settings_file).read())[\"settings\"]\n",
    "dbAddress = settings['db_file']\n",
    "\n",
    "datasets = [settings['json_folder']+fname for fname in os.listdir(settings['json_folder']) if fname.lower().endswith(\".json.gz\")]\n",
    "\n",
    "db = thesisDB(dbAddress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Connect to frog client\n",
    "frog = FrogClient(frogip,frogport,returnall = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08740b3d746e4b779c53f846cfe9f1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Progressbar!\n",
    "f = FloatProgress(min = 0, max = 1, bar_style = 'success')\n",
    "display(f) # display the bar\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_json(dataset, compression = 'gzip')\n",
    "    df.sort_index(inplace = True)\n",
    "    f.description = dataset[54:-8]\n",
    "    f.value = 0\n",
    "    f.max = len(df)\n",
    "    \n",
    "    counter = 0 #commit every 5 documents\n",
    "    for index,row in df.iterrows():\n",
    "        counter += 1\n",
    "\n",
    "        ##First input document, save its rowid for cross-reference\n",
    "        document = {'date':str(row['DATE_dt']),\n",
    "               'medium':enclose(row['MEDIUM']),\n",
    "               'headline':enclose(row['HEADLINE']),\n",
    "               'length':str(row['LENGTH'])}\n",
    "        if row['BYLINE']: #sometimes byline is None\n",
    "            document['byline'] = enclose(row['BYLINE'])\n",
    "        if row['SECTION']: #sometimes sections is None\n",
    "            document['section'] = enclose(row['SECTION'])\n",
    "        if counter % 10 == 0:\n",
    "            lastRow = db.insertRow('documents',document)\n",
    "        else:\n",
    "            lastRow = db.insertRow('documents',document,False)\n",
    "\n",
    "        paragraph_no = 1\n",
    "\n",
    "        entities = []\n",
    "        entity = ['','']\n",
    "\n",
    "        for paragraph in row['TEXT']:\n",
    "\n",
    "            res = frog.process(paragraph)\n",
    "\n",
    "            position = 1\n",
    "            for row in res:\n",
    "                if row[0] is None:\n",
    "                    continue\n",
    "\n",
    "                if row[0] == '\"':\n",
    "                    row = list(row)\n",
    "                    row[0] = 'DOUBLE_QUOTE'\n",
    "                    row[1] = 'DOUBLE_QUOTE'\n",
    "                    row = tuple(row)\n",
    "                data = {\n",
    "                    'token':enclose(row[0]),\n",
    "                    'lemma':enclose(row[1]),\n",
    "                    'paragraph_no':str(paragraph_no),\n",
    "                    'position':str(position),\n",
    "                    'docid':str(lastRow),\n",
    "                    'pos':enclose(re.search('^[A-Z]+',row[3])[0])#, Exclude pos_long because it takes storage and is not needed\n",
    "                    #'pos_long':enclose(row[3])\n",
    "                }\n",
    "\n",
    "                db.insertRow('tokens',data,False)\n",
    "\n",
    "                if row[4] != 'O': #Found an entity\n",
    "                    if re.match('^B-',row[4]) is not None:\n",
    "                        #Entity is new. Save old entity if something is stored\n",
    "                        if entity[0] != '':\n",
    "                            entities.append(entity)\n",
    "                            entity = ['','']\n",
    "                        entity[0] = row[0]\n",
    "                        entity[1] = re.search('[A-Z]+$',row[4])[0]\n",
    "                    else: \n",
    "                        entity[0] += ' '+row[0] #append next term of entity\n",
    "\n",
    "                position += 1\n",
    "            paragraph_no += 1\n",
    "\n",
    "        if entity[0] != '': #append last entity if present\n",
    "            entities.append(entity)\n",
    "\n",
    "        for ent,t in entities:\n",
    "            data = {'entity':enclose(ent),\n",
    "                   'category':enclose(t),\n",
    "                   'docid':str(lastRow)}\n",
    "            db.insertRow('entities',data,False)\n",
    "\n",
    "\n",
    "        f.value += 1\n",
    "    db.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
