{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from VUSentimentLexiconLight import LexiconSent\n",
    "import re\n",
    "import json\n",
    "from sqlite_db import thesisDB, docData, enclose\n",
    "\n",
    "settings_file = 'D:/thesis/settings - nl.json'\n",
    "db_file = 'D:/thesis/nl/data.db'\n",
    "\n",
    "#Load all necessary pipelines\n",
    "lexicon = LexiconSent('nl')\n",
    "lexicon.negators |= {'niet','geen','nooit'}\n",
    "db = thesisDB(db_file)\n",
    "\n",
    "#POS from frog to lexicon\n",
    "pos_map = {'ADJ' : 'adj', 'BW'  : 'adv', 'LID' : 'other', 'N' : 'noun', 'SPEC' : 'noun', \n",
    "           'TSW' : 'other', 'TW' : 'other', 'VG' : 'other', 'VNW' : 'other', 'VZ' : 'prep', 'WW' : 'verb'}\n",
    "sentToInt = lambda x: 1 if x == 'positive' else -1 if x == 'negative' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get lemmatized corpus from the DB\n",
    "cursor = db.getTokens(returnColumns=['lemma','pos','docid','paragraph_no'])\n",
    "\n",
    "corpus = []\n",
    "currentDoc = 1\n",
    "currentParagraph = 1\n",
    "doc = []\n",
    "paragraph = []\n",
    "\n",
    "for lemma, pos, docid, paragraph_no in cursor:\n",
    "    if docid != currentDoc and doc: #We hit a new document!\n",
    "        doc.append(paragraph)\n",
    "        corpus.append((currentDoc,doc))\n",
    "        paragraph = []\n",
    "        doc = []\n",
    "        currentDoc = docid\n",
    "        currentParagraph = paragraph_no\n",
    "    elif paragraph_no != currentParagraph and paragraph: #New paragraph!\n",
    "        doc.append(paragraph)\n",
    "        paragraph = []\n",
    "        currentParagraph = paragraph_no\n",
    "    if pos != 'LET':\n",
    "        paragraph.append((lemma,pos_map[pos]))\n",
    "\n",
    "doc.append(paragraph)\n",
    "corpus.append((currentDoc,doc))\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pick keywords to signal discussion of EU matters. Keep in mind that these are lemmas!\n",
    "keywords = ['europees unie','EU','Brussel','europees parlement','europees commissie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Reconstruct the corpus to fit in the sentiment polarity tagger.\n",
    "words = sorted(keywords, key = len) #Count doesn't matter, so neither does order here.\n",
    "words = [r'\\b'+word+r'\\b' for word in words] #Append word borders so we don't match substrings\n",
    "EU_words = re.compile('|'.join(words))\n",
    "del words\n",
    "\n",
    "corpus_eu = []\n",
    "for docid,doc in corpus:\n",
    "    newdoc = []\n",
    "    for paragraph in doc:\n",
    "        if re.search(EU_words,' '.join([lemma for lemma,pos in paragraph])):\n",
    "            newdoc.append(paragraph)\n",
    "    corpus_eu.append((docid,newdoc))\n",
    "del docid,doc,newdoc,EU_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "for docid,doc in corpus_eu:\n",
    "    docSents = []\n",
    "    for paragraph in doc:\n",
    "        lemmas = [lemma for lemma,pos in paragraph]\n",
    "        postags = [pos for lemma,pos in paragraph]\n",
    "        docSents.append(sentToInt(lexicon.getDocSentiment(lemmas,postags,spacyPos = False)))\n",
    "    sentiment.append((docid,docSents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696915657441973"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set()\n",
    "a |= {1}\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
