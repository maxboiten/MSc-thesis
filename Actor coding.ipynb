{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding actors\n",
    "\n",
    "Actors are counted using NER. Two categories are then used: PERSON and ORGANIZATION.\n",
    "\n",
    "The process has three steps:\n",
    "1. Summarising the unique actors and listing these in a separate data file\n",
    "2. Coding them \n",
    "3. Counting them automatically\n",
    "\n",
    "#### Category selection\n",
    "The choice is made to select only PERSON and ORGANIZATION for coding. The CoreNLP NER is good enough to separate these. If they are confused, they often seem to fit in each other's categories. The MISC category catches whatever is left that is obviously not a date, number, ordinal or location. If there are false negatives, they should be there. The category, however, is fairly large. Therefore, for initial coding the PERSON and ORGANIZATION tags should suffice.\n",
    "\n",
    "#### Counting\n",
    "Counting is rather tedious in this case, because names of actors might overlap and therefore lead to double counting. Consider the following few options. These strings overlap in multiple situation. Firstly, all overlap with 'Council', leading to double counting. Secondly, 'Council of Ministers' overlaps with 'Council of Ministers Committee of Permanent Representatives', leading to triple counting.\n",
    "\n",
    "```\n",
    "Council\n",
    "Council Presidency\n",
    "Council of 16\n",
    "Council of Europe\n",
    "Council of General Affairs\n",
    "Council of Ministers\n",
    "Council of Ministers Committee of Permanent Representatives\n",
    "Council of the European Union\n",
    "Council of the Union\n",
    "```\n",
    "\n",
    "This is overcome using `re.findall()`, which finds all non-overlapping matches. The regular expression is built up using or statements (e.g. `'Council Presidency|Council'`), where regex **takes only the first match** from the pattern if they overlap. Therefore, to find the unique matches, ignoring overlapping substrings, the different entities have to be sorted by length before bulding the pattern. To clarify, consider the following:\n",
    "\n",
    "```Python\n",
    "sentence = 'This sentence is about the Council Presidency'\n",
    "print(re.findall('Council Presidency|Council',sentence))\n",
    "# ['Council Presidency']\n",
    "print(re.findall('Council|Council Presidency',sentence))\n",
    "# ['Council']\n",
    "```\n",
    "\n",
    "The former is correct, hence the sorting. The pattern is precompiled in order to save computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from ner_methods import *\n",
    "import re\n",
    "import codingtools\n",
    "\n",
    "corenlp_ram = '2g'\n",
    "settings_file = 'D:/thesis/settings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preparation\n",
    "\n",
    "#Read settings\n",
    "settings = json.loads(open(settings_file).read())[\"settings\"]\n",
    "\n",
    "#Read data\n",
    "df = pd.read_csv(settings['data_csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors occurred on indices: 0, 31, 32, 44, 45, 87\n",
      "Entities were found in the following categories: MISC, PERSON, PERCENT, DATE, ORGANIZATION, NUMBER, LOCATION, DURATION, TIME, ORDINAL, MONEY, SET\n"
     ]
    }
   ],
   "source": [
    "#Unique named entities\n",
    "uniqueEntities = set()\n",
    "\n",
    "counter = 0\n",
    "errorList = []\n",
    "\n",
    "with StanfordCoreNLP(settings['corenlp_dir'], memory = corenlp_ram) as nlp:\n",
    "    for text in df['TEXT']:\n",
    "        try: #Sometimes texts give errors, e.g. when different alphabets are used. Therefore list those.\n",
    "            uniqueEntities.update(getUniqueEntities(text,nlp))\n",
    "        except:\n",
    "            errorList.append(str(counter))\n",
    "        counter += 1\n",
    "\n",
    "print(\"Errors occurred on indices:\",\", \".join(errorList))\n",
    "\n",
    "##Sort entities into categories\n",
    "entity_map = {}\n",
    "\n",
    "for (entity,entity_type) in uniqueEntities:\n",
    "    if entity_type not in entity_map: #Set element to the correct data format to then add elements\n",
    "        entity_map[entity_type] = set()\n",
    "        \n",
    "    entity_map[entity_type].add(entity)\n",
    "    \n",
    "print(\"Entities were found in the following categories:\",\", \".join(entity_map.keys()))\n",
    "\n",
    "##Save output of uncoded actors to CSV, sorted alphabetically\n",
    "with open(settings['person_csv'],'w+') as f:\n",
    "    for person in sorted(entity_map['PERSON']):\n",
    "        f.write(person+'\\n')\n",
    "\n",
    "with open(settings['org_csv'],'w+') as f:\n",
    "    for org in sorted(entity_map['ORGANIZATION']):\n",
    "        f.write(org+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coding actors\n",
    "import codingtools\n",
    "\n",
    "categories = ['EU political actor','National political actor','Other nationality, political','Non-political']\n",
    "to_code = entity_map['PERSON']\n",
    "\n",
    "coding = codingtools.codingTool(to_code,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffcdc58aa96498482a419b456a0f15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coding.code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
